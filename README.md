# A SMART Mnemonic Sounds like â€œGlue Tonicâ€: Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick

This repository contains the code, data, and pre-trained models for our Arxiv paper: **A SMART Mnemonic Sounds like â€œGlue Tonicâ€: Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick**

[ğŸ¦¾ [Model]() / ğŸ“Š Data / ğŸ“ Paper]

<img href=/image/Mnemonic_Figure.svg></img>


## Mnemonic Datasets
- Mnemonic Fine-tuning Data: https://huggingface.co/datasets/nbalepur/Mnemonic_SFT
- Mnemonic Student Preferences Data: https://huggingface.co/datasets/nbalepur/Mnemonic_Pref
- Mnemonic Test Set: https://huggingface.co/datasets/nbalepur/Mnemonic_Test

## Pre-trained SMART Models
- SMART Tokenizer: https://huggingface.co/datasets/nbalepur/LLama-2-70b-Mnemonic-Tokenizer
- SMART Fine-tuned: https://huggingface.co/nbalepur/LLama-2-70b-Mnemonic-SFT
- SMART DPO: https://huggingface.co/nbalepur/LLama-2-70b-Mnemonic-DPO/
